{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b55e978-a09f-42de-8340-d36da0c1ba47",
   "metadata": {},
   "source": [
    "!/usr/bin/env python\n",
    "\n",
    "**Logo Generation LoRA Training for SD 1.5 - No PEFT, No bitsandbytes**\n",
    "**=================================================================**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d80450c0-2f54-4e56-96e8-23cdc839182f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/logo_train/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importing required Dependencies\n",
    "\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint\n",
    "import numpy as np\n",
    "import types\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import transformers\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import set_seed\n",
    "from diffusers import (\n",
    "    AutoencoderKL,\n",
    "    DDPMScheduler,\n",
    "    StableDiffusionPipeline,\n",
    "    UNet2DConditionModel,\n",
    ")\n",
    "from diffusers.loaders import AttnProcsLayers\n",
    "from diffusers.models.attention_processor import LoRAAttnProcessor\n",
    "from diffusers.optimization import get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa79ffc-549f-4551-8d63-c50720d3b63d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),\n",
    "        logging.FileHandler(f\"lora_training_{datetime.now().strftime('%Y%m%d_%H%M')}.log\")\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "282c48eb-cb27-4715-856d-60c704f6b2d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "class TrainingConfig:\n",
    "    def __init__(self):\n",
    "        # Model settings\n",
    "        self.pretrained_model_name = \"runwayml/stable-diffusion-v1-5\"\n",
    "        self.output_dir = \"models/sd15_lora_logos\"\n",
    "        \n",
    "        # LoRA settings\n",
    "        self.lora_rank = 128\n",
    "        self.lora_alpha = 128  # Often same as rank\n",
    "        self.lora_dropout = 0.0\n",
    "        \n",
    "        # Training settings\n",
    "        self.seed = 42\n",
    "        self.resolution = 512\n",
    "        self.train_batch_size = 4\n",
    "        self.mixed_precision = \"fp16\"  # \"no\" for full precision\n",
    "        self.gradient_accumulation_steps = 4\n",
    "        self.gradient_checkpointing = True\n",
    "        \n",
    "        # Learning rate and scheduler\n",
    "        self.learning_rate = 1e-4\n",
    "        self.lr_scheduler = \"cosine\"\n",
    "        self.lr_warmup_steps = 100\n",
    "        self.lr_num_cycles = 1\n",
    "        self.lr_power = 1.0\n",
    "        \n",
    "        # Training loop\n",
    "        self.max_train_steps = 10000\n",
    "        self.checkpointing_steps = 1000\n",
    "        self.validation_steps = 250\n",
    "        self.validation_prompt = \"A logo for a technology company, minimalist style, with blue colors\"\n",
    "        \n",
    "        # Dataset settings\n",
    "        self.dataset_path = \"data/processed_modern\"\n",
    "        self.training_data_json = os.path.join(self.dataset_path, \"modern_training_data.json\")\n",
    "        \n",
    "        # Performance\n",
    "        self.enable_xformers = True\n",
    "        self.dataloader_num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4e511ed-0f3a-408f-afd3-a6a49b5b9857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LogoDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        json_path,\n",
    "        tokenizer,\n",
    "        size=512,\n",
    "        center_crop=True,\n",
    "        random_flip=True,\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.size = size\n",
    "        self.center_crop = center_crop\n",
    "        self.random_flip = random_flip\n",
    "        \n",
    "        logger.info(f\"Loading dataset from {json_path}\")\n",
    "        with open(json_path, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "        \n",
    "        # Getting path information\n",
    "        self.dataset_dir = os.path.dirname(json_path)\n",
    "        \n",
    "        logger.info(f\"Loaded {len(self.data)} training samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        # Getting image path\n",
    "        filename = item[\"file_name\"]\n",
    "        is_augmented = item.get(\"augmented\", False)\n",
    "        \n",
    "        # FIXED: Get correct path based on filename pattern\n",
    "        if \"_aug\" in filename:\n",
    "            # If filename contains '_aug', it's definitely an augmented file\n",
    "            image_path = os.path.join(self.dataset_dir, \"augmented_images\", filename)\n",
    "        else:\n",
    "            # Otherwise it's a regular file in the images directory\n",
    "            image_path = os.path.join(self.dataset_dir, \"images\", filename)\n",
    "        \n",
    "        # Double-checking if the file exists\n",
    "        if not os.path.exists(image_path):\n",
    "            raise FileNotFoundError(f\"Image file not found: {image_path}\")\n",
    "        \n",
    "        # Getting the prompt\n",
    "        caption = item[\"prompt\"]\n",
    "        \n",
    "        # Loading and transform the image\n",
    "        image = Image.open(image_path)\n",
    "        if not image.mode == \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        \n",
    "        # Applying transformations\n",
    "        if self.center_crop:\n",
    "            image = self.center_crop_image(image, self.size)\n",
    "        \n",
    "        if self.random_flip and random.random() > 0.5:\n",
    "            image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        \n",
    "        # Converting to tensor\n",
    "        image = np.array(image).astype(np.uint8)\n",
    "        image = (image / 127.5 - 1.0).astype(np.float32)\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1)  # Moving channels to first dim\n",
    "        \n",
    "        # Tokenize caption\n",
    "        inputs = self.tokenizer(\n",
    "            caption,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.tokenizer.model_max_length,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"pixel_values\": image,\n",
    "            \"input_ids\": inputs.input_ids[0],\n",
    "            \"image_path\": image_path,\n",
    "            \"caption\": caption,\n",
    "        }\n",
    "    \n",
    "    def center_crop_image(self, image, size):\n",
    "        width, height = image.size\n",
    "        new_size = min(width, height)\n",
    "        left = (width - new_size) // 2\n",
    "        top = (height - new_size) // 2\n",
    "        right = left + new_size\n",
    "        bottom = top + new_size\n",
    "        image = image.crop((left, top, right, bottom))\n",
    "        return image.resize((size, size), Image.BICUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfa1773d-92f7-4213-aefe-0f5b88066c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_lora_layers(unet, rank=4, alpha=4):\n",
    "    \"\"\"Creating LoRA layers for self-attention modules only\"\"\"\n",
    "    from diffusers.models.lora import LoRALinearLayer\n",
    "    import torch.nn.functional as F\n",
    "    \n",
    "    # Get LoRA-compatible modules\n",
    "    lora_modules = {}\n",
    "    \n",
    "    # Finding all self-attention modules\n",
    "    for name, module in unet.named_modules():\n",
    "        # Focus only on self-attention (attn1) modules\n",
    "        if isinstance(module, torch.nn.Linear) and \"attn1\" in name and any(\n",
    "            x in name for x in [\"to_q\", \"to_k\", \"to_v\", \"to_out.0\"]\n",
    "        ):\n",
    "            lora_modules[name] = module\n",
    "    \n",
    "    logger.info(f\"Found {len(lora_modules)} LoRA-compatible modules\")\n",
    "    \n",
    "    # Creating a list to store trainable parameters\n",
    "    lora_parameters = []\n",
    "    \n",
    "    # Creating custom LoRA forwarding wrapper\n",
    "    class LoRAWrapper(torch.nn.Module):\n",
    "        def __init__(self, base_layer, rank, alpha):\n",
    "            super().__init__()\n",
    "            self.base_layer = base_layer\n",
    "            self.in_features = base_layer.in_features\n",
    "            self.out_features = base_layer.out_features\n",
    "            \n",
    "            # Initialize LoRA weights\n",
    "            self.lora_down = torch.nn.Linear(self.in_features, rank, bias=False)\n",
    "            self.lora_up = torch.nn.Linear(rank, self.out_features, bias=False)\n",
    "            \n",
    "            # Initializing weights - this is important for stability\n",
    "            torch.nn.init.normal_(self.lora_down.weight, std=1/rank)\n",
    "            torch.nn.init.zeros_(self.lora_up.weight)\n",
    "            \n",
    "            # Scaling factor\n",
    "            self.scale = alpha / rank\n",
    "            \n",
    "            # Disable gradient computation for base layer\n",
    "            for param in self.base_layer.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        def forward(self, x):\n",
    "            # Base forward pass\n",
    "            base_output = self.base_layer(x)\n",
    "            \n",
    "            # LoRA forward pass\n",
    "            lora_output = self.lora_up(F.relu(self.lora_down(x))) * self.scale\n",
    "            \n",
    "            # Combining outputs\n",
    "            return base_output + lora_output\n",
    "    \n",
    "    # Replacing modules with LoRA wrappers\n",
    "    count = 0\n",
    "    for name, module in lora_modules.items():\n",
    "        # Creating LoRA wrapper\n",
    "        lora_wrapper = LoRAWrapper(module, rank, alpha)\n",
    "        \n",
    "        # Moving to same device and dtype\n",
    "        lora_wrapper = lora_wrapper.to(module.weight.device, module.weight.dtype)\n",
    "        \n",
    "        # Setting parameters to require gradients\n",
    "        lora_wrapper.lora_down.weight.requires_grad_(True)\n",
    "        lora_wrapper.lora_up.weight.requires_grad_(True)\n",
    "        \n",
    "        # Adding parameters to trainable list\n",
    "        lora_parameters.append(lora_wrapper.lora_down.weight)\n",
    "        lora_parameters.append(lora_wrapper.lora_up.weight)\n",
    "        \n",
    "        # Finding parent module\n",
    "        parent_name, child_name = name.rsplit(\".\", 1)\n",
    "        parent = unet\n",
    "        for part in parent_name.split(\".\"):\n",
    "            parent = getattr(parent, part)\n",
    "        \n",
    "        # Replacing module with wrapper\n",
    "        setattr(parent, child_name, lora_wrapper)\n",
    "        count += 1\n",
    "    \n",
    "    logger.info(f\"Replaced {count} modules with LoRA wrappers\")\n",
    "    logger.info(f\"Number of trainable parameters: {sum(p.numel() for p in lora_parameters)}\")\n",
    "    \n",
    "    return lora_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8efacc79-aca8-4173-9456-6fd082ac91e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_lora(unet, save_path, rank=128, alpha=128):\n",
    "    \"\"\"Save LoRA weights and config\"\"\"\n",
    "    # Saving path\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    # Extracting LoRA state dict\n",
    "    lora_state_dict = {}\n",
    "    \n",
    "    # Finding all LoRA wrappers\n",
    "    for name, module in unet.named_modules():\n",
    "        if hasattr(module, 'lora_up') and hasattr(module, 'lora_down'):\n",
    "            # Saving the weights\n",
    "            lora_state_dict[f\"{name}.lora_down.weight\"] = module.lora_down.weight.data.clone()\n",
    "            lora_state_dict[f\"{name}.lora_up.weight\"] = module.lora_up.weight.data.clone()\n",
    "            \n",
    "            # Converting scale to tensor if it exists\n",
    "            if hasattr(module, 'scale'):\n",
    "                # Convert float to tensor\n",
    "                scale_tensor = torch.tensor(module.scale, dtype=torch.float32)\n",
    "                lora_state_dict[f\"{name}.scale\"] = scale_tensor\n",
    "    \n",
    "    # Saving the state dict\n",
    "    lora_path = os.path.join(save_path, \"pytorch_lora_weights.safetensors\")\n",
    "    \n",
    "    # Using safetensors for storing weights\n",
    "    try:\n",
    "        from safetensors.torch import save_file\n",
    "        save_file(lora_state_dict, lora_path)\n",
    "    except ImportError:\n",
    "        # Fallback to PyTorch saving if safetensors not available\n",
    "        torch.save(lora_state_dict, lora_path.replace(\"safetensors\", \"bin\"))\n",
    "        logger.warning(\"safetensors not available, saved weights using torch.save instead\")\n",
    "    \n",
    "    # Saving config for weights\n",
    "    config = {\n",
    "        \"model_type\": \"stable-diffusion\",\n",
    "        \"base_model_name\": \"runwayml/stable-diffusion-v1-5\",\n",
    "        \"rank\": rank,\n",
    "        \"network_alpha\": alpha\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(save_path, \"config.json\"), \"w\") as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    logger.info(f\"Saved LoRA weights to {save_path}\")\n",
    "    return lora_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34d3ffa1-72b5-43cb-804e-b18c57f614af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 15:41:50,620 - INFO - Found 2 CUDA devices\n",
      "2025-05-02 15:41:50,632 - INFO - Using GPU: NVIDIA L4\n",
      "2025-05-02 15:41:50,634 - INFO - Starting LoRA training for SD 1.5\n",
      "2025-05-02 15:41:51,865 - INFO - Found 64 LoRA-compatible modules\n",
      "2025-05-02 15:41:52,047 - INFO - Replaced 64 modules with LoRA wrappers\n",
      "2025-05-02 15:41:52,049 - INFO - Number of trainable parameters: 12779520\n",
      "2025-05-02 15:41:52,050 - INFO - Loading dataset from data/processed_modern/modern_training_data.json\n",
      "2025-05-02 15:41:52,058 - INFO - Loaded 3212 training samples\n",
      "2025-05-02 15:41:53,529 - INFO - Using xformers for memory efficient attention\n",
      "2025-05-02 15:41:53,530 - INFO - ***** Running LoRA training *****\n",
      "2025-05-02 15:41:53,531 - INFO -   Num examples = 3212\n",
      "2025-05-02 15:41:53,531 - INFO -   Instantaneous batch size per device = 4\n",
      "2025-05-02 15:41:53,532 - INFO -   Total train batch size = 16\n",
      "2025-05-02 15:41:53,533 - INFO -   Gradient Accumulation steps = 4\n",
      "2025-05-02 15:41:53,533 - INFO -   Total optimization steps = 10000\n",
      "2025-05-02 15:41:53,534 - INFO -   Output directory = models/sd15_lora_logos\n",
      "2025-05-02 15:41:53,535 - INFO -   Mixed precision = fp16\n",
      "  0%|          | 50/10000 [01:31<4:29:10,  1.62s/it]2025-05-02 15:43:25,004 - INFO - Step 50: loss = 0.0227, lr = 0.00002500\n",
      "  1%|          | 100/10000 [03:01<4:29:30,  1.63s/it]2025-05-02 15:44:54,673 - INFO - Step 100: loss = 0.0125, lr = 0.00005000\n",
      "  2%|▏         | 150/10000 [04:30<4:28:29,  1.64s/it]2025-05-02 15:46:24,334 - INFO - Step 150: loss = 0.0078, lr = 0.00007500\n",
      "  2%|▏         | 200/10000 [06:00<4:26:32,  1.63s/it]2025-05-02 15:47:54,036 - INFO - Step 200: loss = 0.0179, lr = 0.00010000\n",
      "  2%|▎         | 250/10000 [07:30<4:25:46,  1.64s/it]2025-05-02 15:49:23,662 - INFO - Step 250: loss = 0.0350, lr = 0.00010000\n",
      "  3%|▎         | 300/10000 [08:59<4:24:08,  1.63s/it]2025-05-02 15:50:53,350 - INFO - Step 300: loss = 0.0077, lr = 0.00009999\n",
      "  4%|▎         | 350/10000 [10:29<4:22:33,  1.63s/it]2025-05-02 15:52:23,096 - INFO - Step 350: loss = 0.0154, lr = 0.00009999\n",
      "  4%|▍         | 400/10000 [11:59<4:21:56,  1.64s/it]2025-05-02 15:53:52,795 - INFO - Step 400: loss = 0.0268, lr = 0.00009997\n",
      "  4%|▍         | 450/10000 [13:28<4:20:12,  1.63s/it]2025-05-02 15:55:22,006 - INFO - Step 450: loss = 0.0085, lr = 0.00009996\n",
      "  5%|▌         | 500/10000 [14:58<4:18:49,  1.63s/it]2025-05-02 15:56:51,727 - INFO - Step 500: loss = 0.0214, lr = 0.00009994\n",
      "  6%|▌         | 550/10000 [16:27<4:17:32,  1.64s/it]2025-05-02 15:58:21,298 - INFO - Step 550: loss = 0.0109, lr = 0.00009992\n",
      "  6%|▌         | 600/10000 [17:57<4:15:51,  1.63s/it]2025-05-02 15:59:50,975 - INFO - Step 600: loss = 0.0047, lr = 0.00009990\n",
      "  6%|▋         | 650/10000 [19:27<4:14:40,  1.63s/it]2025-05-02 16:01:20,747 - INFO - Step 650: loss = 0.0134, lr = 0.00009987\n",
      "  7%|▋         | 700/10000 [20:56<4:13:47,  1.64s/it]2025-05-02 16:02:50,420 - INFO - Step 700: loss = 0.0216, lr = 0.00009984\n",
      "  8%|▊         | 750/10000 [22:26<4:11:43,  1.63s/it]2025-05-02 16:04:20,074 - INFO - Step 750: loss = 0.0100, lr = 0.00009981\n",
      "  8%|▊         | 800/10000 [23:56<4:10:24,  1.63s/it]2025-05-02 16:05:49,766 - INFO - Step 800: loss = 0.0159, lr = 0.00009977\n",
      "  8%|▊         | 850/10000 [25:25<4:10:42,  1.64s/it]2025-05-02 16:07:19,107 - INFO - Step 850: loss = 0.0234, lr = 0.00009973\n",
      "  9%|▉         | 900/10000 [26:55<4:07:59,  1.64s/it]2025-05-02 16:08:48,802 - INFO - Step 900: loss = 0.0127, lr = 0.00009969\n",
      " 10%|▉         | 950/10000 [28:24<4:06:23,  1.63s/it]2025-05-02 16:10:18,476 - INFO - Step 950: loss = 0.0060, lr = 0.00009965\n",
      " 10%|█         | 1000/10000 [29:54<4:05:09,  1.63s/it]2025-05-02 16:11:48,199 - INFO - Step 1000: loss = 0.0110, lr = 0.00009960\n",
      "2025-05-02 16:11:48,516 - INFO - Saved LoRA weights to models/sd15_lora_logos/checkpoint-1000\n",
      "2025-05-02 16:11:48,517 - INFO - Saved checkpoint at step 1000 to models/sd15_lora_logos/checkpoint-1000\n",
      " 10%|█         | 1050/10000 [31:24<4:03:29,  1.63s/it]2025-05-02 16:13:18,221 - INFO - Step 1050: loss = 0.0180, lr = 0.00009955\n",
      " 11%|█         | 1100/10000 [32:54<4:02:14,  1.63s/it]2025-05-02 16:14:47,948 - INFO - Step 1100: loss = 0.0315, lr = 0.00009949\n",
      " 12%|█▏        | 1150/10000 [34:24<4:00:50,  1.63s/it]2025-05-02 16:16:17,672 - INFO - Step 1150: loss = 0.0137, lr = 0.00009943\n",
      " 12%|█▏        | 1200/10000 [35:53<3:59:54,  1.64s/it]2025-05-02 16:17:47,409 - INFO - Step 1200: loss = 0.0163, lr = 0.00009937\n",
      " 12%|█▎        | 1250/10000 [37:23<3:58:04,  1.63s/it]2025-05-02 16:19:16,604 - INFO - Step 1250: loss = 0.0109, lr = 0.00009931\n",
      " 13%|█▎        | 1300/10000 [38:52<3:57:03,  1.63s/it]2025-05-02 16:20:46,214 - INFO - Step 1300: loss = 0.0085, lr = 0.00009924\n",
      " 14%|█▎        | 1350/10000 [40:22<3:55:44,  1.64s/it]2025-05-02 16:22:15,958 - INFO - Step 1350: loss = 0.0064, lr = 0.00009917\n",
      " 14%|█▍        | 1400/10000 [41:52<3:54:39,  1.64s/it]2025-05-02 16:23:45,622 - INFO - Step 1400: loss = 0.0079, lr = 0.00009910\n",
      " 14%|█▍        | 1450/10000 [43:21<3:52:57,  1.63s/it]2025-05-02 16:25:15,348 - INFO - Step 1450: loss = 0.0054, lr = 0.00009902\n",
      " 15%|█▌        | 1500/10000 [44:51<3:51:36,  1.63s/it]2025-05-02 16:26:45,139 - INFO - Step 1500: loss = 0.0090, lr = 0.00009894\n",
      " 16%|█▌        | 1550/10000 [46:21<3:50:02,  1.63s/it]2025-05-02 16:28:14,795 - INFO - Step 1550: loss = 0.0102, lr = 0.00009886\n",
      " 16%|█▌        | 1600/10000 [47:50<3:48:57,  1.64s/it]2025-05-02 16:29:44,518 - INFO - Step 1600: loss = 0.0314, lr = 0.00009877\n",
      " 16%|█▋        | 1650/10000 [49:20<3:47:26,  1.63s/it]2025-05-02 16:31:13,758 - INFO - Step 1650: loss = 0.0216, lr = 0.00009868\n",
      " 17%|█▋        | 1700/10000 [50:49<3:46:19,  1.64s/it]2025-05-02 16:32:43,499 - INFO - Step 1700: loss = 0.0322, lr = 0.00009859\n",
      " 18%|█▊        | 1750/10000 [52:19<3:45:13,  1.64s/it]2025-05-02 16:34:13,260 - INFO - Step 1750: loss = 0.0298, lr = 0.00009850\n",
      " 18%|█▊        | 1800/10000 [53:49<3:43:42,  1.64s/it]2025-05-02 16:35:43,044 - INFO - Step 1800: loss = 0.0160, lr = 0.00009840\n",
      " 18%|█▊        | 1850/10000 [55:19<3:42:14,  1.64s/it]2025-05-02 16:37:12,812 - INFO - Step 1850: loss = 0.0185, lr = 0.00009830\n",
      " 19%|█▉        | 1900/10000 [56:49<3:41:01,  1.64s/it]2025-05-02 16:38:42,606 - INFO - Step 1900: loss = 0.0078, lr = 0.00009819\n",
      " 20%|█▉        | 1950/10000 [58:18<3:39:51,  1.64s/it]2025-05-02 16:40:12,417 - INFO - Step 1950: loss = 0.0149, lr = 0.00009808\n",
      " 20%|██        | 2000/10000 [59:48<3:38:06,  1.64s/it]2025-05-02 16:41:42,251 - INFO - Step 2000: loss = 0.0187, lr = 0.00009797\n",
      "2025-05-02 16:41:42,380 - INFO - Saved LoRA weights to models/sd15_lora_logos/checkpoint-2000\n",
      "2025-05-02 16:41:42,382 - INFO - Saved checkpoint at step 2000 to models/sd15_lora_logos/checkpoint-2000\n",
      " 20%|██        | 2050/10000 [1:01:18<3:36:54,  1.64s/it]2025-05-02 16:43:11,611 - INFO - Step 2050: loss = 0.0269, lr = 0.00009786\n",
      " 21%|██        | 2100/10000 [1:02:47<3:35:28,  1.64s/it]2025-05-02 16:44:41,389 - INFO - Step 2100: loss = 0.0300, lr = 0.00009775\n",
      " 22%|██▏       | 2150/10000 [1:04:17<3:33:52,  1.63s/it]2025-05-02 16:46:11,097 - INFO - Step 2150: loss = 0.0369, lr = 0.00009763\n",
      " 22%|██▏       | 2200/10000 [1:05:47<3:32:25,  1.63s/it]2025-05-02 16:47:40,865 - INFO - Step 2200: loss = 0.0170, lr = 0.00009750\n",
      " 22%|██▎       | 2250/10000 [1:07:17<3:31:30,  1.64s/it]2025-05-02 16:49:10,651 - INFO - Step 2250: loss = 0.0049, lr = 0.00009738\n",
      " 23%|██▎       | 2300/10000 [1:08:46<3:29:52,  1.64s/it]2025-05-02 16:50:40,418 - INFO - Step 2300: loss = 0.0095, lr = 0.00009725\n",
      " 24%|██▎       | 2350/10000 [1:10:16<3:28:32,  1.64s/it]2025-05-02 16:52:10,230 - INFO - Step 2350: loss = 0.0160, lr = 0.00009712\n",
      " 24%|██▍       | 2400/10000 [1:11:46<3:27:14,  1.64s/it]2025-05-02 16:53:39,995 - INFO - Step 2400: loss = 0.0721, lr = 0.00009698\n",
      " 24%|██▍       | 2450/10000 [1:13:15<3:25:58,  1.64s/it]2025-05-02 16:55:09,290 - INFO - Step 2450: loss = 0.0132, lr = 0.00009685\n",
      " 25%|██▌       | 2500/10000 [1:14:45<3:24:26,  1.64s/it]2025-05-02 16:56:38,984 - INFO - Step 2500: loss = 0.0208, lr = 0.00009671\n",
      " 26%|██▌       | 2550/10000 [1:16:15<3:23:11,  1.64s/it]2025-05-02 16:58:08,745 - INFO - Step 2550: loss = 0.0122, lr = 0.00009656\n",
      " 26%|██▌       | 2600/10000 [1:17:44<3:21:29,  1.63s/it]2025-05-02 16:59:38,521 - INFO - Step 2600: loss = 0.0426, lr = 0.00009642\n",
      " 26%|██▋       | 2650/10000 [1:19:14<3:20:10,  1.63s/it]2025-05-02 17:01:08,205 - INFO - Step 2650: loss = 0.0132, lr = 0.00009627\n",
      " 27%|██▋       | 2700/10000 [1:20:44<3:19:00,  1.64s/it]2025-05-02 17:02:37,946 - INFO - Step 2700: loss = 0.0451, lr = 0.00009612\n",
      " 28%|██▊       | 2750/10000 [1:22:14<3:17:37,  1.64s/it]2025-05-02 17:04:07,686 - INFO - Step 2750: loss = 0.0206, lr = 0.00009596\n",
      " 28%|██▊       | 2800/10000 [1:23:43<3:16:42,  1.64s/it]2025-05-02 17:05:37,475 - INFO - Step 2800: loss = 0.0155, lr = 0.00009581\n",
      " 28%|██▊       | 2850/10000 [1:25:13<3:14:50,  1.64s/it]2025-05-02 17:07:06,702 - INFO - Step 2850: loss = 0.0325, lr = 0.00009564\n",
      " 29%|██▉       | 2900/10000 [1:26:42<3:13:18,  1.63s/it]2025-05-02 17:08:36,413 - INFO - Step 2900: loss = 0.0072, lr = 0.00009548\n",
      " 30%|██▉       | 2950/10000 [1:28:12<3:12:15,  1.64s/it]2025-05-02 17:10:06,217 - INFO - Step 2950: loss = 0.0116, lr = 0.00009532\n",
      " 30%|███       | 3000/10000 [1:29:42<3:10:33,  1.63s/it]2025-05-02 17:11:35,965 - INFO - Step 3000: loss = 0.0270, lr = 0.00009515\n",
      "2025-05-02 17:11:36,095 - INFO - Saved LoRA weights to models/sd15_lora_logos/checkpoint-3000\n",
      "2025-05-02 17:11:36,096 - INFO - Saved checkpoint at step 3000 to models/sd15_lora_logos/checkpoint-3000\n",
      " 30%|███       | 3050/10000 [1:31:12<3:09:19,  1.63s/it]2025-05-02 17:13:05,831 - INFO - Step 3050: loss = 0.0210, lr = 0.00009497\n",
      " 31%|███       | 3100/10000 [1:32:42<3:07:59,  1.63s/it]2025-05-02 17:14:35,600 - INFO - Step 3100: loss = 0.0242, lr = 0.00009480\n",
      " 32%|███▏      | 3150/10000 [1:34:11<3:06:59,  1.64s/it]2025-05-02 17:16:05,349 - INFO - Step 3150: loss = 0.0187, lr = 0.00009462\n",
      " 32%|███▏      | 3200/10000 [1:35:41<3:05:35,  1.64s/it]2025-05-02 17:17:35,136 - INFO - Step 3200: loss = 0.0190, lr = 0.00009444\n",
      " 32%|███▎      | 3250/10000 [1:37:10<3:03:47,  1.63s/it]2025-05-02 17:19:04,214 - INFO - Step 3250: loss = 0.0285, lr = 0.00009426\n",
      " 33%|███▎      | 3300/10000 [1:38:40<3:02:32,  1.63s/it]2025-05-02 17:20:33,959 - INFO - Step 3300: loss = 0.0257, lr = 0.00009407\n",
      " 34%|███▎      | 3350/10000 [1:40:10<3:01:21,  1.64s/it]2025-05-02 17:22:03,714 - INFO - Step 3350: loss = 0.0037, lr = 0.00009388\n",
      " 34%|███▍      | 3400/10000 [1:41:39<2:59:45,  1.63s/it]2025-05-02 17:23:33,411 - INFO - Step 3400: loss = 0.0185, lr = 0.00009369\n",
      " 34%|███▍      | 3450/10000 [1:43:09<2:58:32,  1.64s/it]2025-05-02 17:25:03,195 - INFO - Step 3450: loss = 0.0194, lr = 0.00009350\n",
      " 35%|███▌      | 3500/10000 [1:44:39<2:57:01,  1.63s/it]2025-05-02 17:26:32,965 - INFO - Step 3500: loss = 0.0260, lr = 0.00009330\n",
      " 36%|███▌      | 3550/10000 [1:46:09<2:55:54,  1.64s/it]2025-05-02 17:28:02,638 - INFO - Step 3550: loss = 0.0086, lr = 0.00009310\n",
      " 36%|███▌      | 3600/10000 [1:47:38<2:54:14,  1.63s/it]2025-05-02 17:29:32,326 - INFO - Step 3600: loss = 0.0049, lr = 0.00009290\n",
      " 36%|███▋      | 3650/10000 [1:49:08<2:53:10,  1.64s/it]2025-05-02 17:31:01,620 - INFO - Step 3650: loss = 0.0088, lr = 0.00009269\n",
      " 37%|███▋      | 3700/10000 [1:50:37<2:51:38,  1.63s/it]2025-05-02 17:32:31,325 - INFO - Step 3700: loss = 0.0194, lr = 0.00009249\n",
      " 38%|███▊      | 3750/10000 [1:52:07<2:50:18,  1.63s/it]2025-05-02 17:34:00,966 - INFO - Step 3750: loss = 0.0166, lr = 0.00009228\n",
      " 38%|███▊      | 3800/10000 [1:53:37<2:48:41,  1.63s/it]2025-05-02 17:35:30,695 - INFO - Step 3800: loss = 0.0282, lr = 0.00009206\n",
      " 38%|███▊      | 3850/10000 [1:55:06<2:47:38,  1.64s/it]2025-05-02 17:37:00,425 - INFO - Step 3850: loss = 0.0088, lr = 0.00009185\n",
      " 39%|███▉      | 3900/10000 [1:56:36<2:46:25,  1.64s/it]2025-05-02 17:38:30,133 - INFO - Step 3900: loss = 0.0274, lr = 0.00009163\n",
      " 40%|███▉      | 3950/10000 [1:58:06<2:44:54,  1.64s/it]2025-05-02 17:39:59,826 - INFO - Step 3950: loss = 0.0176, lr = 0.00009141\n",
      " 40%|████      | 4000/10000 [1:59:36<2:43:43,  1.64s/it]2025-05-02 17:41:29,559 - INFO - Step 4000: loss = 0.1016, lr = 0.00009118\n",
      "2025-05-02 17:41:29,686 - INFO - Saved LoRA weights to models/sd15_lora_logos/checkpoint-4000\n",
      "2025-05-02 17:41:29,687 - INFO - Saved checkpoint at step 4000 to models/sd15_lora_logos/checkpoint-4000\n",
      " 40%|████      | 4050/10000 [2:01:05<2:42:05,  1.63s/it]2025-05-02 17:42:58,948 - INFO - Step 4050: loss = 0.0153, lr = 0.00009096\n",
      " 41%|████      | 4100/10000 [2:02:35<2:40:47,  1.64s/it]2025-05-02 17:44:28,772 - INFO - Step 4100: loss = 0.0634, lr = 0.00009073\n",
      " 42%|████▏     | 4150/10000 [2:04:05<2:40:19,  1.64s/it]2025-05-02 17:45:58,598 - INFO - Step 4150: loss = 0.0093, lr = 0.00009050\n",
      " 42%|████▏     | 4200/10000 [2:05:34<2:38:23,  1.64s/it]2025-05-02 17:47:28,403 - INFO - Step 4200: loss = 0.0193, lr = 0.00009026\n",
      " 42%|████▎     | 4250/10000 [2:07:04<2:36:55,  1.64s/it]2025-05-02 17:48:58,252 - INFO - Step 4250: loss = 0.0162, lr = 0.00009003\n",
      " 43%|████▎     | 4300/10000 [2:08:34<2:35:20,  1.64s/it]2025-05-02 17:50:28,018 - INFO - Step 4300: loss = 0.0271, lr = 0.00008979\n",
      " 44%|████▎     | 4350/10000 [2:10:04<2:34:15,  1.64s/it]2025-05-02 17:51:57,833 - INFO - Step 4350: loss = 0.0923, lr = 0.00008955\n",
      " 44%|████▍     | 4400/10000 [2:11:34<2:32:59,  1.64s/it]2025-05-02 17:53:27,607 - INFO - Step 4400: loss = 0.0324, lr = 0.00008930\n",
      " 44%|████▍     | 4450/10000 [2:13:03<2:33:51,  1.66s/it]2025-05-02 17:54:56,974 - INFO - Step 4450: loss = 0.0153, lr = 0.00008906\n",
      " 45%|████▌     | 4500/10000 [2:14:33<2:29:59,  1.64s/it]2025-05-02 17:56:26,722 - INFO - Step 4500: loss = 0.0093, lr = 0.00008881\n",
      " 46%|████▌     | 4550/10000 [2:16:02<2:28:52,  1.64s/it]2025-05-02 17:57:56,523 - INFO - Step 4550: loss = 0.0167, lr = 0.00008856\n",
      " 46%|████▌     | 4600/10000 [2:17:32<2:27:10,  1.64s/it]2025-05-02 17:59:26,274 - INFO - Step 4600: loss = 0.0124, lr = 0.00008830\n",
      " 46%|████▋     | 4650/10000 [2:19:02<2:25:50,  1.64s/it]2025-05-02 18:00:56,102 - INFO - Step 4650: loss = 0.0139, lr = 0.00008805\n",
      " 47%|████▋     | 4700/10000 [2:20:32<2:24:27,  1.64s/it]2025-05-02 18:02:25,926 - INFO - Step 4700: loss = 0.0236, lr = 0.00008779\n",
      " 48%|████▊     | 4750/10000 [2:22:02<2:23:31,  1.64s/it]2025-05-02 18:03:55,762 - INFO - Step 4750: loss = 0.0680, lr = 0.00008753\n",
      " 48%|████▊     | 4800/10000 [2:23:32<2:21:47,  1.64s/it]2025-05-02 18:05:25,573 - INFO - Step 4800: loss = 0.0395, lr = 0.00008726\n",
      " 48%|████▊     | 4850/10000 [2:25:01<2:20:35,  1.64s/it]2025-05-02 18:06:54,865 - INFO - Step 4850: loss = 0.0306, lr = 0.00008700\n",
      " 49%|████▉     | 4900/10000 [2:26:31<2:19:08,  1.64s/it]2025-05-02 18:08:24,754 - INFO - Step 4900: loss = 0.0376, lr = 0.00008673\n",
      " 50%|████▉     | 4950/10000 [2:28:00<2:17:41,  1.64s/it]2025-05-02 18:09:54,539 - INFO - Step 4950: loss = 0.0142, lr = 0.00008646\n",
      " 50%|█████     | 5000/10000 [2:29:30<2:16:15,  1.64s/it]2025-05-02 18:11:24,300 - INFO - Step 5000: loss = 0.0170, lr = 0.00008619\n",
      "2025-05-02 18:11:24,423 - INFO - Saved LoRA weights to models/sd15_lora_logos/checkpoint-5000\n",
      "2025-05-02 18:11:24,425 - INFO - Saved checkpoint at step 5000 to models/sd15_lora_logos/checkpoint-5000\n",
      " 50%|█████     | 5050/10000 [2:31:00<2:14:49,  1.63s/it]2025-05-02 18:12:54,227 - INFO - Step 5050: loss = 0.0198, lr = 0.00008591\n",
      " 51%|█████     | 5100/10000 [2:32:30<2:13:34,  1.64s/it]2025-05-02 18:14:23,972 - INFO - Step 5100: loss = 0.0241, lr = 0.00008563\n",
      " 52%|█████▏    | 5150/10000 [2:34:00<2:12:21,  1.64s/it]2025-05-02 18:15:53,787 - INFO - Step 5150: loss = 0.0110, lr = 0.00008536\n",
      " 52%|█████▏    | 5200/10000 [2:35:30<2:10:57,  1.64s/it]2025-05-02 18:17:23,567 - INFO - Step 5200: loss = 0.0209, lr = 0.00008507\n",
      " 52%|█████▎    | 5250/10000 [2:36:59<2:11:21,  1.66s/it]2025-05-02 18:18:53,081 - INFO - Step 5250: loss = 0.0153, lr = 0.00008479\n",
      " 53%|█████▎    | 5300/10000 [2:38:29<2:08:06,  1.64s/it]2025-05-02 18:20:22,925 - INFO - Step 5300: loss = 0.0209, lr = 0.00008450\n",
      " 54%|█████▎    | 5350/10000 [2:39:59<2:06:54,  1.64s/it]2025-05-02 18:21:52,712 - INFO - Step 5350: loss = 0.0074, lr = 0.00008422\n",
      " 54%|█████▍    | 5400/10000 [2:41:29<2:05:39,  1.64s/it]2025-05-02 18:23:22,552 - INFO - Step 5400: loss = 0.0139, lr = 0.00008393\n",
      " 55%|█████▍    | 5450/10000 [2:42:58<2:04:07,  1.64s/it]2025-05-02 18:24:52,304 - INFO - Step 5450: loss = 0.0165, lr = 0.00008363\n",
      " 55%|█████▌    | 5500/10000 [2:44:28<2:02:39,  1.64s/it]2025-05-02 18:26:22,125 - INFO - Step 5500: loss = 0.0315, lr = 0.00008334\n",
      " 56%|█████▌    | 5550/10000 [2:46:16<2:02:56,  1.66s/it]2025-05-02 18:28:09,930 - INFO - Step 5550: loss = 0.0209, lr = 0.00008304\n",
      " 56%|█████▌    | 5600/10000 [2:47:46<2:00:03,  1.64s/it]2025-05-02 18:29:39,748 - INFO - Step 5600: loss = 0.0145, lr = 0.00008274\n",
      " 56%|█████▋    | 5650/10000 [2:49:15<1:58:50,  1.64s/it]2025-05-02 18:31:09,082 - INFO - Step 5650: loss = 0.0323, lr = 0.00008244\n",
      " 57%|█████▋    | 5700/10000 [2:51:03<1:57:14,  1.64s/it]2025-05-02 18:32:56,808 - INFO - Step 5700: loss = 0.0131, lr = 0.00008214\n",
      " 57%|█████▊    | 5750/10000 [2:52:33<1:55:47,  1.63s/it]2025-05-02 18:34:26,603 - INFO - Step 5750: loss = 0.0098, lr = 0.00008183\n",
      " 58%|█████▊    | 5800/10000 [2:54:20<1:56:10,  1.66s/it]2025-05-02 18:36:14,440 - INFO - Step 5800: loss = 0.0174, lr = 0.00008153\n",
      " 58%|█████▊    | 5850/10000 [2:55:50<1:53:18,  1.64s/it]2025-05-02 18:37:44,247 - INFO - Step 5850: loss = 0.0064, lr = 0.00008122\n",
      " 59%|█████▉    | 5900/10000 [2:57:20<1:51:43,  1.63s/it]2025-05-02 18:39:13,928 - INFO - Step 5900: loss = 0.0100, lr = 0.00008091\n",
      " 60%|█████▉    | 5950/10000 [2:58:50<1:50:28,  1.64s/it]2025-05-02 18:40:43,714 - INFO - Step 5950: loss = 0.0187, lr = 0.00008060\n",
      " 60%|██████    | 6000/10000 [3:00:38<2:17:42,  2.07s/it]2025-05-02 18:42:31,551 - INFO - Step 6000: loss = 0.0054, lr = 0.00008028\n",
      "2025-05-02 18:42:31,676 - INFO - Saved LoRA weights to models/sd15_lora_logos/checkpoint-6000\n",
      "2025-05-02 18:42:31,677 - INFO - Saved checkpoint at step 6000 to models/sd15_lora_logos/checkpoint-6000\n",
      " 60%|██████    | 6050/10000 [3:02:07<1:47:38,  1.64s/it]2025-05-02 18:44:00,892 - INFO - Step 6050: loss = 0.0279, lr = 0.00007996\n",
      " 61%|██████    | 6100/10000 [3:03:37<1:46:30,  1.64s/it]2025-05-02 18:45:30,740 - INFO - Step 6100: loss = 0.0098, lr = 0.00007965\n",
      " 62%|██████▏   | 6150/10000 [3:05:07<1:44:54,  1.64s/it]2025-05-02 18:47:00,555 - INFO - Step 6150: loss = 0.0379, lr = 0.00007933\n",
      " 62%|██████▏   | 6200/10000 [3:06:36<1:43:45,  1.64s/it]2025-05-02 18:48:30,362 - INFO - Step 6200: loss = 0.0232, lr = 0.00007900\n",
      " 62%|██████▎   | 6250/10000 [3:08:06<1:42:08,  1.63s/it]2025-05-02 18:50:00,081 - INFO - Step 6250: loss = 0.0175, lr = 0.00007868\n",
      " 63%|██████▎   | 6300/10000 [3:09:36<1:40:50,  1.64s/it]2025-05-02 18:51:29,880 - INFO - Step 6300: loss = 0.0178, lr = 0.00007835\n",
      " 64%|██████▎   | 6350/10000 [3:11:06<1:40:18,  1.65s/it]2025-05-02 18:52:59,696 - INFO - Step 6350: loss = 0.0168, lr = 0.00007803\n",
      " 64%|██████▍   | 6400/10000 [3:12:35<1:38:04,  1.63s/it]2025-05-02 18:54:29,413 - INFO - Step 6400: loss = 0.0064, lr = 0.00007770\n",
      " 64%|██████▍   | 6450/10000 [3:14:05<1:36:43,  1.63s/it]2025-05-02 18:55:58,643 - INFO - Step 6450: loss = 0.0098, lr = 0.00007736\n",
      " 65%|██████▌   | 6500/10000 [3:15:34<1:35:22,  1.64s/it]2025-05-02 18:57:28,414 - INFO - Step 6500: loss = 0.0320, lr = 0.00007703\n",
      " 66%|██████▌   | 6550/10000 [3:17:04<1:34:01,  1.64s/it]2025-05-02 18:58:58,197 - INFO - Step 6550: loss = 0.0248, lr = 0.00007670\n",
      " 66%|██████▌   | 6600/10000 [3:18:34<1:32:38,  1.63s/it]2025-05-02 19:00:27,948 - INFO - Step 6600: loss = 0.0089, lr = 0.00007636\n",
      " 66%|██████▋   | 6650/10000 [3:20:04<1:31:21,  1.64s/it]2025-05-02 19:01:57,828 - INFO - Step 6650: loss = 0.0243, lr = 0.00007602\n",
      " 67%|██████▋   | 6700/10000 [3:21:33<1:29:59,  1.64s/it]2025-05-02 19:03:27,510 - INFO - Step 6700: loss = 0.0154, lr = 0.00007568\n",
      " 68%|██████▊   | 6750/10000 [3:23:03<1:28:30,  1.63s/it]2025-05-02 19:04:57,257 - INFO - Step 6750: loss = 0.0195, lr = 0.00007534\n",
      " 68%|██████▊   | 6800/10000 [3:24:33<1:27:15,  1.64s/it]2025-05-02 19:06:27,071 - INFO - Step 6800: loss = 0.0168, lr = 0.00007500\n",
      " 68%|██████▊   | 6850/10000 [3:26:02<1:25:47,  1.63s/it]2025-05-02 19:07:56,231 - INFO - Step 6850: loss = 0.0339, lr = 0.00007466\n",
      " 69%|██████▉   | 6900/10000 [3:27:32<1:24:31,  1.64s/it]2025-05-02 19:09:26,004 - INFO - Step 6900: loss = 0.0291, lr = 0.00007431\n",
      " 70%|██████▉   | 6950/10000 [3:29:02<1:23:06,  1.63s/it]2025-05-02 19:10:55,743 - INFO - Step 6950: loss = 0.0150, lr = 0.00007396\n",
      " 70%|███████   | 7000/10000 [3:30:31<1:21:46,  1.64s/it]2025-05-02 19:12:25,522 - INFO - Step 7000: loss = 0.0670, lr = 0.00007361\n",
      "2025-05-02 19:12:25,648 - INFO - Saved LoRA weights to models/sd15_lora_logos/checkpoint-7000\n",
      "2025-05-02 19:12:25,649 - INFO - Saved checkpoint at step 7000 to models/sd15_lora_logos/checkpoint-7000\n",
      " 70%|███████   | 7050/10000 [3:32:01<1:20:23,  1.64s/it]2025-05-02 19:13:55,393 - INFO - Step 7050: loss = 0.0200, lr = 0.00007326\n",
      " 71%|███████   | 7100/10000 [3:33:31<1:18:59,  1.63s/it]2025-05-02 19:15:25,146 - INFO - Step 7100: loss = 0.0275, lr = 0.00007291\n",
      " 72%|███████▏  | 7150/10000 [3:35:01<1:17:55,  1.64s/it]2025-05-02 19:16:54,937 - INFO - Step 7150: loss = 0.0139, lr = 0.00007256\n",
      " 72%|███████▏  | 7200/10000 [3:36:31<1:16:18,  1.64s/it]2025-05-02 19:18:24,709 - INFO - Step 7200: loss = 0.0347, lr = 0.00007220\n",
      " 72%|███████▎  | 7250/10000 [3:38:00<1:14:55,  1.63s/it]2025-05-02 19:19:53,921 - INFO - Step 7250: loss = 0.0275, lr = 0.00007185\n",
      " 73%|███████▎  | 7300/10000 [3:39:30<1:13:42,  1.64s/it]2025-05-02 19:21:23,773 - INFO - Step 7300: loss = 0.0268, lr = 0.00007149\n",
      " 74%|███████▎  | 7350/10000 [3:41:00<1:12:18,  1.64s/it]2025-05-02 19:22:53,540 - INFO - Step 7350: loss = 0.0172, lr = 0.00007113\n",
      " 74%|███████▍  | 7400/10000 [3:42:29<1:10:52,  1.64s/it]2025-05-02 19:24:23,334 - INFO - Step 7400: loss = 0.0282, lr = 0.00007077\n",
      " 74%|███████▍  | 7450/10000 [3:43:59<1:09:36,  1.64s/it]2025-05-02 19:25:53,087 - INFO - Step 7450: loss = 0.0367, lr = 0.00007041\n",
      " 75%|███████▌  | 7500/10000 [3:45:29<1:08:11,  1.64s/it]2025-05-02 19:27:22,814 - INFO - Step 7500: loss = 0.0184, lr = 0.00007005\n",
      " 76%|███████▌  | 7550/10000 [3:46:59<1:06:44,  1.63s/it]2025-05-02 19:28:52,607 - INFO - Step 7550: loss = 0.0093, lr = 0.00006968\n",
      " 76%|███████▌  | 7600/10000 [3:48:28<1:05:22,  1.63s/it]2025-05-02 19:30:22,370 - INFO - Step 7600: loss = 0.0119, lr = 0.00006932\n",
      " 76%|███████▋  | 7650/10000 [3:49:57<1:03:56,  1.63s/it]2025-05-02 19:31:51,473 - INFO - Step 7650: loss = 0.0182, lr = 0.00006895\n",
      " 77%|███████▋  | 7700/10000 [3:51:27<1:02:58,  1.64s/it]2025-05-02 19:33:21,324 - INFO - Step 7700: loss = 0.0099, lr = 0.00006858\n",
      " 78%|███████▊  | 7750/10000 [3:52:57<1:01:19,  1.64s/it]2025-05-02 19:34:51,096 - INFO - Step 7750: loss = 0.0315, lr = 0.00006821\n",
      " 78%|███████▊  | 7800/10000 [3:54:27<59:55,  1.63s/it]  2025-05-02 19:36:20,845 - INFO - Step 7800: loss = 0.0110, lr = 0.00006784\n",
      " 78%|███████▊  | 7850/10000 [3:55:57<58:31,  1.63s/it]  2025-05-02 19:37:50,546 - INFO - Step 7850: loss = 0.0125, lr = 0.00006747\n",
      " 79%|███████▉  | 7900/10000 [3:57:26<57:15,  1.64s/it]  2025-05-02 19:39:20,328 - INFO - Step 7900: loss = 0.0122, lr = 0.00006710\n",
      " 80%|███████▉  | 7950/10000 [3:58:56<55:54,  1.64s/it]  2025-05-02 19:40:50,019 - INFO - Step 7950: loss = 0.0146, lr = 0.00006673\n",
      " 80%|████████  | 8000/10000 [4:00:26<54:32,  1.64s/it]  2025-05-02 19:42:19,829 - INFO - Step 8000: loss = 0.0102, lr = 0.00006635\n",
      "2025-05-02 19:42:19,956 - INFO - Saved LoRA weights to models/sd15_lora_logos/checkpoint-8000\n",
      "2025-05-02 19:42:19,957 - INFO - Saved checkpoint at step 8000 to models/sd15_lora_logos/checkpoint-8000\n",
      " 80%|████████  | 8050/10000 [4:01:55<53:02,  1.63s/it]  2025-05-02 19:43:49,224 - INFO - Step 8050: loss = 0.0168, lr = 0.00006598\n",
      " 81%|████████  | 8100/10000 [4:03:25<51:50,  1.64s/it]  2025-05-02 19:45:19,163 - INFO - Step 8100: loss = 0.0106, lr = 0.00006560\n",
      " 82%|████████▏ | 8150/10000 [4:04:55<50:25,  1.64s/it]  2025-05-02 19:46:48,949 - INFO - Step 8150: loss = 0.0213, lr = 0.00006522\n",
      " 82%|████████▏ | 8200/10000 [4:06:25<49:03,  1.64s/it]  2025-05-02 19:48:18,799 - INFO - Step 8200: loss = 0.0252, lr = 0.00006485\n",
      " 82%|████████▎ | 8250/10000 [4:07:55<47:43,  1.64s/it]2025-05-02 19:49:48,625 - INFO - Step 8250: loss = 0.0167, lr = 0.00006447\n",
      " 83%|████████▎ | 8300/10000 [4:09:24<46:22,  1.64s/it]2025-05-02 19:51:18,450 - INFO - Step 8300: loss = 0.0341, lr = 0.00006409\n",
      " 84%|████████▎ | 8350/10000 [4:10:54<45:00,  1.64s/it]2025-05-02 19:52:48,327 - INFO - Step 8350: loss = 0.0421, lr = 0.00006371\n",
      " 84%|████████▍ | 8400/10000 [4:12:24<43:36,  1.64s/it]2025-05-02 19:54:18,180 - INFO - Step 8400: loss = 0.0159, lr = 0.00006332\n",
      " 84%|████████▍ | 8450/10000 [4:13:53<42:10,  1.63s/it]2025-05-02 19:55:47,391 - INFO - Step 8450: loss = 0.0170, lr = 0.00006294\n",
      " 85%|████████▌ | 8500/10000 [4:15:23<40:56,  1.64s/it]2025-05-02 19:57:17,201 - INFO - Step 8500: loss = 0.0252, lr = 0.00006256\n",
      " 86%|████████▌ | 8550/10000 [4:16:53<39:33,  1.64s/it]2025-05-02 19:58:47,069 - INFO - Step 8550: loss = 0.0161, lr = 0.00006217\n",
      " 86%|████████▌ | 8600/10000 [4:18:23<38:12,  1.64s/it]2025-05-02 20:00:16,891 - INFO - Step 8600: loss = 0.0195, lr = 0.00006179\n",
      " 86%|████████▋ | 8650/10000 [4:19:53<36:53,  1.64s/it]2025-05-02 20:01:46,814 - INFO - Step 8650: loss = 0.0147, lr = 0.00006140\n",
      " 87%|████████▋ | 8700/10000 [4:21:23<35:28,  1.64s/it]2025-05-02 20:03:16,664 - INFO - Step 8700: loss = 0.0237, lr = 0.00006102\n",
      " 88%|████████▊ | 8750/10000 [4:22:52<34:06,  1.64s/it]2025-05-02 20:04:46,496 - INFO - Step 8750: loss = 0.0205, lr = 0.00006063\n",
      " 88%|████████▊ | 8800/10000 [4:24:22<32:43,  1.64s/it]2025-05-02 20:06:16,325 - INFO - Step 8800: loss = 0.0249, lr = 0.00006024\n",
      " 88%|████████▊ | 8850/10000 [4:25:52<31:18,  1.63s/it]2025-05-02 20:07:45,640 - INFO - Step 8850: loss = 0.0365, lr = 0.00005985\n",
      " 89%|████████▉ | 8900/10000 [4:27:21<30:03,  1.64s/it]2025-05-02 20:09:15,469 - INFO - Step 8900: loss = 0.0119, lr = 0.00005946\n",
      " 90%|████████▉ | 8950/10000 [4:28:51<28:40,  1.64s/it]2025-05-02 20:10:45,319 - INFO - Step 8950: loss = 0.0077, lr = 0.00005907\n",
      " 90%|█████████ | 9000/10000 [4:30:21<27:14,  1.63s/it]2025-05-02 20:12:15,200 - INFO - Step 9000: loss = 0.0127, lr = 0.00005868\n",
      "2025-05-02 20:12:15,347 - INFO - Saved LoRA weights to models/sd15_lora_logos/checkpoint-9000\n",
      "2025-05-02 20:12:15,349 - INFO - Saved checkpoint at step 9000 to models/sd15_lora_logos/checkpoint-9000\n",
      " 90%|█████████ | 9050/10000 [4:31:51<25:53,  1.63s/it]2025-05-02 20:13:45,176 - INFO - Step 9050: loss = 0.0066, lr = 0.00005829\n",
      " 91%|█████████ | 9100/10000 [4:33:21<24:34,  1.64s/it]2025-05-02 20:15:15,031 - INFO - Step 9100: loss = 0.0234, lr = 0.00005790\n",
      " 92%|█████████▏| 9150/10000 [4:34:51<23:12,  1.64s/it]2025-05-02 20:16:44,922 - INFO - Step 9150: loss = 0.0160, lr = 0.00005751\n",
      " 92%|█████████▏| 9200/10000 [4:36:21<21:48,  1.64s/it]2025-05-02 20:18:14,737 - INFO - Step 9200: loss = 0.0296, lr = 0.00005712\n",
      " 92%|█████████▎| 9250/10000 [4:37:50<20:15,  1.62s/it]2025-05-02 20:19:43,900 - INFO - Step 9250: loss = 0.0164, lr = 0.00005672\n",
      " 93%|█████████▎| 9300/10000 [4:39:20<19:03,  1.63s/it]2025-05-02 20:21:13,721 - INFO - Step 9300: loss = 0.0100, lr = 0.00005633\n",
      " 94%|█████████▎| 9350/10000 [4:40:50<17:46,  1.64s/it]2025-05-02 20:22:43,551 - INFO - Step 9350: loss = 0.0191, lr = 0.00005594\n",
      " 94%|█████████▍| 9400/10000 [4:42:19<16:21,  1.64s/it]2025-05-02 20:24:13,384 - INFO - Step 9400: loss = 0.0046, lr = 0.00005554\n",
      " 94%|█████████▍| 9450/10000 [4:43:49<14:58,  1.63s/it]2025-05-02 20:25:43,222 - INFO - Step 9450: loss = 0.0127, lr = 0.00005515\n",
      " 95%|█████████▌| 9500/10000 [4:45:19<13:38,  1.64s/it]2025-05-02 20:27:13,020 - INFO - Step 9500: loss = 0.0324, lr = 0.00005475\n",
      " 96%|█████████▌| 9550/10000 [4:46:49<12:17,  1.64s/it]2025-05-02 20:28:42,878 - INFO - Step 9550: loss = 0.0118, lr = 0.00005436\n",
      " 96%|█████████▌| 9600/10000 [4:48:19<10:53,  1.63s/it]2025-05-02 20:30:12,665 - INFO - Step 9600: loss = 0.0090, lr = 0.00005396\n",
      " 96%|█████████▋| 9650/10000 [4:49:48<09:22,  1.61s/it]2025-05-02 20:31:41,884 - INFO - Step 9650: loss = 0.0087, lr = 0.00005357\n",
      " 97%|█████████▋| 9700/10000 [4:51:18<08:10,  1.64s/it]2025-05-02 20:33:11,776 - INFO - Step 9700: loss = 0.0365, lr = 0.00005317\n",
      " 98%|█████████▊| 9750/10000 [4:52:48<06:49,  1.64s/it]2025-05-02 20:34:41,593 - INFO - Step 9750: loss = 0.0233, lr = 0.00005278\n",
      " 98%|█████████▊| 9800/10000 [4:54:17<05:27,  1.64s/it]2025-05-02 20:36:11,409 - INFO - Step 9800: loss = 0.0826, lr = 0.00005238\n",
      " 98%|█████████▊| 9850/10000 [4:55:47<04:05,  1.64s/it]2025-05-02 20:37:41,261 - INFO - Step 9850: loss = 0.0135, lr = 0.00005198\n",
      " 99%|█████████▉| 9900/10000 [4:57:17<02:43,  1.64s/it]2025-05-02 20:39:11,051 - INFO - Step 9900: loss = 0.0203, lr = 0.00005159\n",
      "100%|█████████▉| 9950/10000 [4:58:47<01:21,  1.64s/it]2025-05-02 20:40:40,864 - INFO - Step 9950: loss = 0.0159, lr = 0.00005119\n",
      "100%|██████████| 10000/10000 [5:00:17<00:00,  1.64s/it]2025-05-02 20:42:10,627 - INFO - Step 10000: loss = 0.0059, lr = 0.00005079\n",
      "2025-05-02 20:42:10,738 - INFO - Saved LoRA weights to models/sd15_lora_logos/checkpoint-10000\n",
      "2025-05-02 20:42:10,740 - INFO - Saved checkpoint at step 10000 to models/sd15_lora_logos/checkpoint-10000\n",
      "2025-05-02 20:42:10,854 - INFO - Saved LoRA weights to models/sd15_lora_logos/final\n",
      "2025-05-02 20:42:10,856 - INFO - Training completed. Final model saved to models/sd15_lora_logos/final\n",
      "100%|██████████| 10000/10000 [5:00:17<00:00,  1.80s/it]\n",
      "2025-05-02 20:42:10,862 - INFO - Training completed. Model saved to models/sd15_lora_logos\n"
     ]
    }
   ],
   "source": [
    "def train_lora():\n",
    "    \"\"\"Main LoRA training function\"\"\"\n",
    "    # Loading config\n",
    "    config = TrainingConfig()\n",
    "    \n",
    "    # Initializing accelerator\n",
    "    accelerator = Accelerator(\n",
    "        gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "        mixed_precision=config.mixed_precision,\n",
    "    )\n",
    "    \n",
    "    # Setting up logging for accelerator\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    "    )\n",
    "    \n",
    "    # Making output directory\n",
    "    if accelerator.is_main_process:\n",
    "        if config.output_dir is not None:\n",
    "            os.makedirs(config.output_dir, exist_ok=True)\n",
    "    \n",
    "    # Set seed for reproducibility\n",
    "    set_seed(config.seed)\n",
    "    \n",
    "    # Loading tokenizer\n",
    "    tokenizer = CLIPTokenizer.from_pretrained(\n",
    "        config.pretrained_model_name,\n",
    "        subfolder=\"tokenizer\"\n",
    "    )\n",
    "    \n",
    "    # Loading models\n",
    "    noise_scheduler = DDPMScheduler.from_pretrained(\n",
    "        config.pretrained_model_name,\n",
    "        subfolder=\"scheduler\"\n",
    "    )\n",
    "    \n",
    "    text_encoder = CLIPTextModel.from_pretrained(\n",
    "        config.pretrained_model_name,\n",
    "        subfolder=\"text_encoder\",\n",
    "    )\n",
    "    \n",
    "    vae = AutoencoderKL.from_pretrained(\n",
    "        config.pretrained_model_name,\n",
    "        subfolder=\"vae\"\n",
    "    )\n",
    "    \n",
    "    unet = UNet2DConditionModel.from_pretrained(\n",
    "        config.pretrained_model_name,\n",
    "        subfolder=\"unet\"\n",
    "    )\n",
    "    \n",
    "    # Freezing models (only LoRA parameters will be trained)\n",
    "    vae.requires_grad_(False)\n",
    "    text_encoder.requires_grad_(False)\n",
    "    unet.requires_grad_(False)\n",
    "    \n",
    "    # Enabling gradient checkpointing for memory efficiency\n",
    "    if config.gradient_checkpointing:\n",
    "        unet.enable_gradient_checkpointing()\n",
    "    \n",
    "    # Creating LoRA layers\n",
    "    lora_parameters = create_lora_layers(\n",
    "        unet, \n",
    "        rank=config.lora_rank, \n",
    "        alpha=config.lora_alpha\n",
    "    )\n",
    "    \n",
    "    # Creating optimizer\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        lora_parameters,\n",
    "        lr=config.learning_rate,\n",
    "        betas=(0.9, 0.999),\n",
    "        weight_decay=1e-2,\n",
    "        eps=1e-8,\n",
    "    )\n",
    "    \n",
    "    # Creating dataset and dataloader\n",
    "    train_dataset = LogoDataset(\n",
    "        json_path=config.training_data_json,\n",
    "        tokenizer=tokenizer,\n",
    "        size=config.resolution,\n",
    "        center_crop=True,\n",
    "        random_flip=True,\n",
    "    )\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.train_batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=config.dataloader_num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    # Setting up learning rate scheduler\n",
    "    lr_scheduler = get_scheduler(\n",
    "        config.lr_scheduler,\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=config.lr_warmup_steps * accelerator.num_processes,\n",
    "        num_training_steps=config.max_train_steps,\n",
    "        num_cycles=config.lr_num_cycles,\n",
    "        power=config.lr_power,\n",
    "    )\n",
    "    \n",
    "    # Preparing models for accelerator\n",
    "    unet, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
    "        unet, optimizer, train_dataloader, lr_scheduler\n",
    "    )\n",
    "    \n",
    "    # Moving non-optimized models to device\n",
    "    vae.to(accelerator.device)\n",
    "    text_encoder.to(accelerator.device)\n",
    "    \n",
    "    # Enable xformers if requested (memory efficiency)\n",
    "    if config.enable_xformers:\n",
    "        try:\n",
    "            import xformers\n",
    "            unet.enable_xformers_memory_efficient_attention()\n",
    "            logger.info(\"Using xformers for memory efficient attention\")\n",
    "        except ImportError:\n",
    "            logger.warning(\"xformers not available\")\n",
    "    \n",
    "    # Calculating number of steps and set progress bar\n",
    "    num_update_steps_per_epoch = math.ceil(len(train_dataloader) / config.gradient_accumulation_steps)\n",
    "    if config.max_train_steps is None:\n",
    "        config.max_train_steps = config.num_train_epochs * num_update_steps_per_epoch\n",
    "    else:\n",
    "        # Calculatong epochs for info\n",
    "        num_train_epochs = math.ceil(config.max_train_steps / num_update_steps_per_epoch)\n",
    "    \n",
    "    # Getting total batch size\n",
    "    total_batch_size = config.train_batch_size * accelerator.num_processes * config.gradient_accumulation_steps\n",
    "    \n",
    "    # Print training info\n",
    "    logger.info(\"***** Running LoRA training *****\")\n",
    "    logger.info(f\"  Num examples = {len(train_dataset)}\")\n",
    "    logger.info(f\"  Instantaneous batch size per device = {config.train_batch_size}\")\n",
    "    logger.info(f\"  Total train batch size = {total_batch_size}\")\n",
    "    logger.info(f\"  Gradient Accumulation steps = {config.gradient_accumulation_steps}\")\n",
    "    logger.info(f\"  Total optimization steps = {config.max_train_steps}\")\n",
    "    logger.info(f\"  Output directory = {config.output_dir}\")\n",
    "    logger.info(f\"  Mixed precision = {config.mixed_precision}\")\n",
    "    \n",
    "    # Progress bar\n",
    "    progress_bar = tqdm(range(config.max_train_steps), disable=not accelerator.is_local_main_process)\n",
    "    global_step = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(1000):  # Arbitrary large number, we use steps for early stopping\n",
    "        unet.train()\n",
    "        \n",
    "        for batch in train_dataloader:\n",
    "            with accelerator.accumulate(unet):\n",
    "                # Converting images to latent space\n",
    "                with torch.no_grad():\n",
    "                    latents = vae.encode(batch[\"pixel_values\"].to(vae.dtype)).latent_dist.sample() * 0.18215\n",
    "                # Update progress - don't recreate it\n",
    "                if accelerator.sync_gradients:\n",
    "                    progress_bar.update(1)\n",
    "                    global_step += 1\n",
    "                \n",
    "                # Sample noise\n",
    "                noise = torch.randn_like(latents)\n",
    "                bsz = latents.shape[0]\n",
    "                \n",
    "                # Sample a random timestep for each image\n",
    "                timesteps = torch.randint(\n",
    "                    0, noise_scheduler.config.num_train_timesteps, (bsz,), device=latents.device\n",
    "                ).long()\n",
    "                \n",
    "                # Adding noise to the latents\n",
    "                noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
    "                \n",
    "                # Getting text embeddings\n",
    "                with torch.no_grad():\n",
    "                    encoder_hidden_states = text_encoder(batch[\"input_ids\"])[0]\n",
    "                \n",
    "                # Predicting the noise residual\n",
    "                model_pred = unet(\n",
    "                    noisy_latents, timesteps, encoder_hidden_states=encoder_hidden_states\n",
    "                ).sample\n",
    "                \n",
    "                # Calculating loss\n",
    "                loss = F.mse_loss(model_pred, noise, reduction=\"none\").mean([1, 2, 3]).mean()\n",
    "                \n",
    "                # Backward pass and optimization\n",
    "                accelerator.backward(loss)\n",
    "                \n",
    "                if accelerator.sync_gradients:\n",
    "                    accelerator.clip_grad_norm_(lora_parameters, 1.0)\n",
    "                \n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            # Updating progress\n",
    "            if accelerator.sync_gradients:\n",
    "                progress_bar.update(1)\n",
    "                global_step += 1\n",
    "                \n",
    "                # Log progress\n",
    "                if global_step % 50 == 0 and accelerator.is_main_process:\n",
    "                    logger.info(f\"Step {global_step}: loss = {loss.item():.4f}, lr = {lr_scheduler.get_last_lr()[0]:.8f}\")\n",
    "                \n",
    "                # Saving checkpoint\n",
    "                if global_step % config.checkpointing_steps == 0 and accelerator.is_main_process:\n",
    "                    save_path = os.path.join(config.output_dir, f\"checkpoint-{global_step}\")\n",
    "                    os.makedirs(save_path, exist_ok=True)\n",
    "                    \n",
    "                    # Saving LoRA weights\n",
    "                    accelerator.wait_for_everyone()\n",
    "                    unwrapped_unet = accelerator.unwrap_model(unet)\n",
    "                    lora_path = save_lora(unwrapped_unet, save_path)\n",
    "                    \n",
    "                    # Optionally add validation here if desired\n",
    "                    # (would need to load a pipeline and generate samples)\n",
    "                    \n",
    "                    logger.info(f\"Saved checkpoint at step {global_step} to {save_path}\")\n",
    "            \n",
    "            # Checking if we've reached the max steps\n",
    "            if global_step >= config.max_train_steps:\n",
    "                break\n",
    "        \n",
    "        # End epoch - break if we've reached max steps\n",
    "        if global_step >= config.max_train_steps:\n",
    "            break\n",
    "    \n",
    "    # Final save\n",
    "    if accelerator.is_main_process:\n",
    "        # Saving a final checkpoint\n",
    "        save_path = os.path.join(config.output_dir, \"final\")\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        # Unwrap and save\n",
    "        accelerator.wait_for_everyone()\n",
    "        unwrapped_unet = accelerator.unwrap_model(unet)\n",
    "        lora_path = save_lora(unwrapped_unet, save_path, config.lora_rank, config.lora_alpha)\n",
    "        \n",
    "        logger.info(f\"Training completed. Final model saved to {save_path}\")\n",
    "    \n",
    "    # Return the path to the saved model\n",
    "    return config.output_dir\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"Setup environment variables and initial checks before training\"\"\"\n",
    "    # Checking for CUDA\n",
    "    if not torch.cuda.is_available():\n",
    "        logger.warning(\"CUDA not available, training will be slow\")\n",
    "    else:\n",
    "        logger.info(f\"Found {torch.cuda.device_count()} CUDA devices\")\n",
    "        logger.info(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Setting up tensor float precision\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "    \n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Setup\n",
    "    setup_environment()\n",
    "    \n",
    "    # Start training\n",
    "    logger.info(\"Starting LoRA training for SD 1.5\")\n",
    "    output_dir = train_lora()\n",
    "    \n",
    "    logger.info(f\"Training completed. Model saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd10d9c3-40fd-41f6-8763-2aa303a6ef49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def debug_dataset_paths():\n",
    "    \"\"\"Debug dataset paths to ensure files can be found\"\"\"\n",
    "    import json\n",
    "    import os\n",
    "    \n",
    "    # Path to your JSON file\n",
    "    json_path = \"data/processed_modern/modern_training_data.json\"\n",
    "    \n",
    "    # Load the JSON data\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Count total entries\n",
    "    print(f\"Total entries in JSON: {len(data)}\")\n",
    "    \n",
    "    # Check directory structure\n",
    "    base_dir = \"data/processed_modern\"\n",
    "    images_dir = os.path.join(base_dir, \"images\")\n",
    "    augmented_dir = os.path.join(base_dir, \"augmented_images\")\n",
    "    \n",
    "    print(f\"Base directory exists: {os.path.exists(base_dir)}\")\n",
    "    print(f\"Images directory exists: {os.path.exists(images_dir)}\")\n",
    "    print(f\"Augmented images directory exists: {os.path.exists(augmented_dir)}\")\n",
    "    \n",
    "    # Count files in directories\n",
    "    if os.path.exists(images_dir):\n",
    "        image_files = os.listdir(images_dir)\n",
    "        print(f\"Files in images directory: {len(image_files)}\")\n",
    "        \n",
    "    if os.path.exists(augmented_dir):\n",
    "        augmented_files = os.listdir(augmented_dir)\n",
    "        print(f\"Files in augmented_images directory: {len(augmented_files)}\")\n",
    "    \n",
    "    # Verify first 5 entries\n",
    "    print(\"\\nChecking first 5 entries:\")\n",
    "    for i, item in enumerate(data[:5]):\n",
    "        filename = item[\"file_name\"]\n",
    "        is_augmented = item.get(\"augmented\", False)\n",
    "        subfolder = \"augmented_images\" if is_augmented else \"images\"\n",
    "        path = os.path.join(base_dir, subfolder, filename)\n",
    "        \n",
    "        exists = os.path.exists(path)\n",
    "        print(f\"Entry {i}: {filename} (augmented: {is_augmented}) - Path exists: {exists} - {path}\")\n",
    "    \n",
    "    # Verify last 5 entries\n",
    "    print(\"\\nChecking last 5 entries:\")\n",
    "    for i, item in enumerate(data[-5:]):\n",
    "        filename = item[\"file_name\"]\n",
    "        is_augmented = item.get(\"augmented\", False)\n",
    "        subfolder = \"augmented_images\" if is_augmented else \"images\"\n",
    "        path = os.path.join(base_dir, subfolder, filename)\n",
    "        \n",
    "        exists = os.path.exists(path)\n",
    "        print(f\"Entry {i+len(data)-5}: {filename} (augmented: {is_augmented}) - Path exists: {exists} - {path}\")\n",
    "    \n",
    "    # Check for specific problematic file\n",
    "    problem_file = \"modern_490.png\"\n",
    "    direct_path = os.path.join(augmented_dir, problem_file)\n",
    "    print(f\"\\nCheck specific problem file: {direct_path} - Exists: {os.path.exists(direct_path)}\")\n",
    "    \n",
    "    # Search for similar files\n",
    "    if os.path.exists(augmented_dir):\n",
    "        similar_files = [f for f in augmented_files if \"490\" in f]\n",
    "        print(f\"Similar files: {similar_files}\")\n",
    "\n",
    "# Run the function\n",
    "debug_dataset_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3440bb-883e-4fce-b793-c1b4c5f31c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "logo_train",
   "name": "pytorch-gpu.2-4.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/pytorch-gpu.2-4:m129"
  },
  "kernelspec": {
   "display_name": "Logo Training",
   "language": "python",
   "name": "logo_train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
